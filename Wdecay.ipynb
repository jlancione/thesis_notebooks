{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd62a53-5884-4d59-b99d-c0347e72095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('whitegrid')\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab61f184-1faf-4c8d-94e3-8b662993a398",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_testing = 'y'\n",
    "data_checks = 'n' # y -> visualize data and correlation plots (it takes a while to execute the merged pairplot)\n",
    "# preproc_log = 'n' # se lo accendo non impara più nulla, con lo Z invece funziona\n",
    "remove_outliers = True\n",
    "\n",
    "## TRAINING\n",
    "nepochs = 800\n",
    "# choosen_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "choosen_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "# we use \"Sparse\" because classes aren't represented with one hot encoding ie (0,1) e (1,0) but with integers 0 e 1\n",
    "# choosen_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "choosen_loss = 'sparse_categorical_crossentropy'\n",
    " \n",
    "activation = 'sigmoid'\n",
    "\n",
    "\n",
    "# hyperparameters: learning_rate, batch_size, \n",
    "# choice of the optimizer (algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469650be-2e3e-44d1-bcb2-18162541357e",
   "metadata": {},
   "source": [
    "# Features W -> e + nu\n",
    "Run number of the event, Event number, pt eta phi are the electron's kinematics variables, Q is electron's charge, type is where they found the electron (in the barrel or the endcap), the del- features and sigmaEtaEta are the differences between the track variable and the one of the cluster, HoverE is the ratio of the electron's energy measured HCAL/ECAL, iso are parameters associated to electron detection, MET features refer to the kinematics of the neutrino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2aa2655-25ad-4909-849d-283700803c07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfenu_raw = pd.read_csv('~/Documents/tesi/thesis_notebooks/input_datasets/Wenu.csv')\n",
    "dfenu_raw['type'] = dfenu_raw['type'].map({'EB': 0, 'EE': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde6b305-60e0-4fa5-8543-a32ec42fcaad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if data_checks=='y':\n",
    "    dfenu_raw.info()\n",
    "    dfenu_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12875576-8da6-4aac-b40a-182bf0fa8b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to uniform datasets\n",
    "dfenu_raw['iso'] = dfenu_raw.apply(lambda x: x['isoTrack'] + x['isoEcal'] + x['isoHcal'],axis=1)\n",
    "if data_checks=='y':\n",
    "    dfenu_raw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954d01b-fcae-4f61-97f2-36b26d2865e6",
   "metadata": {},
   "source": [
    "## Data visualization, W -> e + nu\n",
    "We will introduce `dfenu_scaled` (numpy array) and `dfenu_array_to_dfenu` (pandas dataframe) for the visualization WITH OUTLIERS, while `dfenu_filtered` and `dfenu_scaled_filtered` are for the visualization WITHOUT OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6779ef-599e-4ebc-9014-7d5044277f30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if data_checks=='y':\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    dfenu_scaled = scaler.fit_transform(dfenu_raw)\n",
    "    dfenu_array_to_dfenu = pd.DataFrame(dfenu_scaled, columns = dfenu_raw.columns)\n",
    "    # aesthetics\n",
    "    plt.figure(figsize=(20, 10)) \n",
    "    sns.set(font_scale=1.0)\n",
    "    # boxplot\n",
    "    sns.boxplot(data=dfenu_array_to_dfenu, orient=\"h\", whis=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb751f-0369-4774-aef9-977c2e4b7ca1",
   "metadata": {},
   "source": [
    "**Boxplot comment**: `pt` e `MET` are the only ones that present *outliers* between the features of interest.\n",
    "\n",
    "**The coloured rectangle covers the range 25-75 quantile, while the whiskers reach to 1.5 times the distance between 25-75th percentile in both directions (starting from the median)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a40cec82-0633-4bb9-bed9-44fa7eddcf94",
   "metadata": {
    "id": "Kcm4xKiZtFPz",
    "outputId": "f919a4ab-984a-431c-9dbe-5bbe3607ce84",
    "papermill": {
     "duration": 1.516093,
     "end_time": "2023-02-17T08:57:28.686454",
     "exception": false,
     "start_time": "2023-02-17T08:57:27.170361",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if data_checks=='y':\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    # sns.set(font_scale=1.0)\n",
    "    sns.heatmap(dfenu_array_to_dfenu.corr() , annot= True, linewidths=2, ax=ax, cmap='mako')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae11b6f-f72b-412a-b8cf-201a6bbf12c2",
   "metadata": {},
   "source": [
    "## Removing outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78431d24-b183-49a1-83db-6d7b74bab1d7",
   "metadata": {},
   "source": [
    "### first from visualization…\n",
    "introducing `cutoff_scal_pt_e` and `cutoff_scal_MET_e` using quantiles (for coherence with the visualization using quantiles through boxplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7e6b15-3574-45d7-82c5-3a0350df4b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_checks == 'y':\n",
    "    cutoff_scal_pt_e = dfenu_array_to_dfenu['pt'].quantile(0.95)\n",
    "    cutoff_scal_MET_e = dfenu_array_to_dfenu['MET'].quantile(0.95)\n",
    "    \n",
    "    dfenu_filtered = dfenu_array_to_dfenu[(dfenu_array_to_dfenu['pt']<cutoff_scal_pt_e) & (dfenu_array_to_dfenu['MET']<cutoff_scal_MET_e)]\n",
    "    print(\"Total number of data points:\\t\\t\" + str(len(dfenu_array_to_dfenu)))\n",
    "    # for troubleshooting\n",
    "    # excluded_e = dfenu_array_to_dfenu[(dfenu_array_to_dfenu['pt']>cutoff_scal_pt_e) | (dfenu_array_to_dfenu['MET']>cutoff_scal_MET_e)]\n",
    "    # print(len(excluded_e))\n",
    "    print(\"Data points after filtering outliers:\\t \" + str(len(dfenu_filtered)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59a8aa64-672f-412a-af92-14412d69e4ca",
   "metadata": {},
   "source": [
    "# this could be another way to filter the outliers but the issue is that their presence influences greatly the standard deviation, so the usage of quantiles has been preferred\n",
    "dfenu_filtered[(np.abs(stats.zscore(dfenu_array_to_dfenu['pt'])) < 1)]  \n",
    "dfenu_filtered[(np.abs(stats.zscore(dfenu_array_to_dfenu['MET'])) < 1)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b8bf25-1e0a-48d0-a8c8-50f2ac438ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if data_checks=='y':\n",
    "    # boxplot again without the outliers\n",
    "    dfenu_scaled_filtered = scaler.fit_transform(dfenu_filtered)\n",
    "    dfenu_filtered = pd.DataFrame(dfenu_scaled_filtered, columns = dfenu_filtered.columns)\n",
    "    # aesthetics\n",
    "    plt.figure(figsize=(20, 10)) \n",
    "    sns.set(font_scale=1.0)\n",
    "    # boxplot\n",
    "    sns.boxplot(data=dfenu_filtered, orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb1bf0-9813-451e-b001-718f5f68f6eb",
   "metadata": {},
   "source": [
    "**NEW boxplot comment**: pt still shows data points out of the whiskers but due to their number, the results of the training, and the sake of keeping as much data as possible they will be kept and considered throughout the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead8963-f2dc-4579-835a-0b9108374ab1",
   "metadata": {},
   "source": [
    "### …then from the real dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2269e51-3216-458e-ae5a-32700f2774c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = dfenu_raw[['pt','eta','phi','Q','iso','MET','phiMET']]\n",
    "\n",
    "if remove_outliers:\n",
    "    cutoff_pt_e = dfe['pt'].quantile(.95)\n",
    "    cutoff_MET_e = dfe['MET'].quantile(.95)\n",
    "    dfe = dfe[(dfe['pt']<cutoff_pt_e) & (dfe['MET']<cutoff_MET_e)]\n",
    "\n",
    "# Adding 'class' because of dataset merging \n",
    "class_col = []\n",
    "for i in range(len(dfe['pt'])):\n",
    "    class_col.append('enu')\n",
    "    \n",
    "dfe.loc[:,'class'] = class_col\n",
    "# len(dfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aac957b1-6cf2-45e1-96df-4198c5a979ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for higher order correlations (this will be repeated after merging the 2 different datasets)\n",
    "if data_checks=='y':\n",
    "    # Unnecessary features already discarded (pairplot on df_e, not df_enu)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.set(font_scale=2.0)\n",
    "    sns.pairplot(dfenu, diag_kind='kde') # stands for Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c640ca-aaea-418d-9f99-3f319d7b5ab9",
   "metadata": {},
   "source": [
    "**Pairplot comment**: the features don't exhibit evident patters, they all seem to carry independent information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0256dc8-974f-483d-9d8d-1f905d0e88bf",
   "metadata": {},
   "source": [
    "# Features W -> mu + nu\n",
    "**Feature comment**: `chisq` is divided by dof, the kinematics features come from fits on data so chisq abnormally high should just be left out of the training of the network, because even if they were decay events they exhibit a peculiar behaviour (like outliers) and the network is not designed to take care of such fine phenomena, `dxy` is the impact parameter, the `iso` parameter represents the threshold for the cluster to be identifyed as the trace/sign of an muon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5dd96fb-c401-4e4e-80d3-f4ff74f24224",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmunu_raw = pd.read_csv('~/Documents/tesi/thesis_notebooks/input_datasets/Wmunu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82accd28-3332-4f80-96f7-9268b87ddab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if data_checks=='y':\n",
    "    dfmunu_raw.info()\n",
    "    dfmunu_raw.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e5e4a-452a-4a78-ac0d-16b9dfe3dff3",
   "metadata": {},
   "source": [
    "Let's get rid of the events with an high chisq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72fb1d2a-4f6f-4a7c-9c6a-0029a6bb8e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4802"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisq_th = 10 # threshold for acceptance of the data. It is a reduced chi squared!\n",
    "not_trustworthy = dfmunu_raw[dfmunu_raw['chiSq'] > chisq_th]\n",
    "len(not_trustworthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e9b11aa-9c03-45fa-a9d2-ecead8802774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfmunu_raw.drop(not_trustworthy.index, inplace=True)\n",
    "# print(len(df_munu[df_munu['chiSq']>100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3e351-f800-46c0-ac70-66b1d1ad2796",
   "metadata": {},
   "source": [
    "## Data visualization, W -> mu + nu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb867e9-02a0-48e6-ac54-2fa6b79db390",
   "metadata": {},
   "source": [
    "We will introduce `dfmunu_scaled` (numpy array) and `dfmunu_array_to_dfenu` (pandas dataframe) for the visualization WITH OUTLIERS, while `dfmunu_filtered` and `dfmunu_scaled_filtered` are for the visualization WITHOUT OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdeead62-0301-49e0-a287-e7e9248c59f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if data_checks=='y':\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    dfmunu_scaled = scaler.fit_transform(dfmunu_raw)\n",
    "    dfmunu_array_to_dfmunu = pd.DataFrame(dfmunu_scaled, columns = dfmunu_raw.columns)\n",
    "    # aesthetics\n",
    "    plt.figure(figsize=(20, 10)) \n",
    "    sns.set(font_scale=1.0)\n",
    "    # boxplot\n",
    "    sns.boxplot(data=dfmunu_array_to_dfmunu, orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9141dd-7279-4fa3-bdaf-aaf57bfa53b7",
   "metadata": {},
   "source": [
    "**Boxplot comment**: `pt` and `MET` are the only relevant features that exhibit outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "836848ac-43bd-40a9-ad14-05373f81f7e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if data_checks=='y':\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    sns.set(font_scale=1.0)\n",
    "    sns.heatmap(dfmunu_array_to_dfmunu.corr() , annot= True, linewidths=3, ax=ax, cmap='mako')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efab35e-5ca9-4fc5-891f-1a9f7d19d5c5",
   "metadata": {},
   "source": [
    "**Heatmap comment**: no relevant (linear) correlations between the features manifest itself at this stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e4581-a42c-4c6d-9e5b-28e3d5d8459a",
   "metadata": {},
   "source": [
    "## Removing outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d23dce-7538-4fd0-8162-ca1908b180b6",
   "metadata": {},
   "source": [
    "### first from visualization…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f93d89b-ef59-48ff-9955-27df18a1651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_checks=='y':\n",
    "    cutoff_scal_pt_mu = dfmunu_array_to_dfmunu['pt'].quantile(0.95)\n",
    "    cutoff_scal_MET_mu = dfmunu_array_to_dfmunu['MET'].quantile(0.95)\n",
    "    \n",
    "    dfmunu_filtered = dfmunu_array_to_dfmunu[(dfmunu_array_to_dfmunu['pt']<cutoff_scal_pt_mu) & (dfmunu_array_to_dfmunu['MET']<cutoff_scal_MET_mu)]\n",
    "    print(\"Total number of data points:\\t\\t\" + str(len(dfmunu_array_to_dfmunu)))\n",
    "    # for troubleshooting\n",
    "    # excluded_mu = dfmunu_array_to_dfmunu[(dfmunu_array_to_dfmunu['pt']>cutoff_scal_pt_mu) | (dfmunu_array_to_dfmunu['MET']>cutoff_scal_MET_mu)]\n",
    "    # print(len(excluded_mu))\n",
    "    print(\"Data points after filtering outliers:\\t\" + str(len(dfmunu_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58c9bb54-d249-4cc2-b8ea-26560d577cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if data_checks=='y':\n",
    "    # boxplot again without outliers\n",
    "    dfmunu_scaled_filtered = scaler.fit_transform(dfmunu_filtered)\n",
    "    dfmunu_filtered = pd.DataFrame(dfmunu_scaled_filtered, columns = dfmunu_filtered.columns)\n",
    "    # aesthetics\n",
    "    plt.figure(figsize=(20, 10)) \n",
    "    sns.set(font_scale=1.0)\n",
    "    # boxplot\n",
    "    sns.boxplot(data=dfmunu_filtered, orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a303cc8-7f22-4660-b2e6-1f58f1428326",
   "metadata": {},
   "source": [
    "**NEW boxplot comment**: here `pt` still shows data out of the whiskers but they will not be considered outliers in the following analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72719b2e-f094-4705-afef-2477cfab5f4d",
   "metadata": {},
   "source": [
    "### … then from the real dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54ab62d7-92b9-4c39-9007-aa435b802366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again in preparation for future merging\n",
    "dfmu = dfmunu_raw[['pt','eta','phi','Q','iso','MET','phiMET']]\n",
    "\n",
    "if remove_outliers:\n",
    "    cutoff_pt_mu = dfmunu_raw['pt'].quantile(.95)\n",
    "    cutoff_MET_mu = dfmunu_raw['MET'].quantile(.95)\n",
    "    dfmu = dfmu[(dfmu['pt']<cutoff_pt_mu) & (dfmu['MET']<cutoff_MET_mu)]\n",
    "\n",
    "class_col = []\n",
    "for i in range(len(dfmu['pt'])):\n",
    "    class_col.append('munu')\n",
    "    \n",
    "dfmu.loc[:,'class'] = class_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06f738ef-4125-4ef0-a587-6939c1a0c696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if data_checks=='y':\n",
    "    # Already discarded unnecessary features (pairplot on dfmu, not dfmunu_raw)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.set(font_scale=2.0)\n",
    "    sns.pairplot(dfmu, diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecbf97f-e636-43dc-a39e-9f7060587cf0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9982013f-f165-411c-8ccb-5e13c6e18ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfenu_raw, dfmunu_raw # clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db96aa43-7656-4cc7-a9b5-22992d254bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pt</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>Q</th>\n",
       "      <th>iso</th>\n",
       "      <th>MET</th>\n",
       "      <th>phiMET</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135421</th>\n",
       "      <td>46.6129</td>\n",
       "      <td>-0.1539</td>\n",
       "      <td>-1.2488</td>\n",
       "      <td>1</td>\n",
       "      <td>18.3840</td>\n",
       "      <td>34.6064</td>\n",
       "      <td>-0.6721</td>\n",
       "      <td>munu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98322</th>\n",
       "      <td>25.4276</td>\n",
       "      <td>-0.6050</td>\n",
       "      <td>-1.9844</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.6338</td>\n",
       "      <td>6.8626</td>\n",
       "      <td>2.8868</td>\n",
       "      <td>munu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162529</th>\n",
       "      <td>32.1379</td>\n",
       "      <td>-0.6763</td>\n",
       "      <td>1.5339</td>\n",
       "      <td>1</td>\n",
       "      <td>89.6808</td>\n",
       "      <td>13.3023</td>\n",
       "      <td>-2.1650</td>\n",
       "      <td>munu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48950</th>\n",
       "      <td>37.7950</td>\n",
       "      <td>0.4799</td>\n",
       "      <td>-1.1036</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8121</td>\n",
       "      <td>23.9980</td>\n",
       "      <td>2.2496</td>\n",
       "      <td>enu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43240</th>\n",
       "      <td>59.8489</td>\n",
       "      <td>2.3550</td>\n",
       "      <td>1.2104</td>\n",
       "      <td>-1</td>\n",
       "      <td>13.2963</td>\n",
       "      <td>25.2738</td>\n",
       "      <td>-1.7519</td>\n",
       "      <td>enu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pt     eta     phi  Q      iso      MET  phiMET class\n",
       "135421  46.6129 -0.1539 -1.2488  1  18.3840  34.6064 -0.6721  munu\n",
       "98322   25.4276 -0.6050 -1.9844 -1   2.6338   6.8626  2.8868  munu\n",
       "162529  32.1379 -0.6763  1.5339  1  89.6808  13.3023 -2.1650  munu\n",
       "48950   37.7950  0.4799 -1.1036  1   2.8121  23.9980  2.2496   enu\n",
       "43240   59.8489  2.3550  1.2104 -1  13.2963  25.2738 -1.7519   enu"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([dfe,dfmu], ignore_index=True, sort=False)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45a35730-772e-4073-bffd-feb922506954",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfe, dfmu # clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4a2df-dce8-4920-b3a9-e1e37ca621e9",
   "metadata": {},
   "source": [
    "## Data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6e4493e-2295-480b-b6f8-8182296a62e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if data_checks=='y':\n",
    "    # Per verificare che il dataset sia bilanciato\n",
    "    sns.countplot(data=df,x='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11a4d416-53c8-4fd3-88ad-f51957fa259c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if data_checks=='y':\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.set(font_scale=2.0)\n",
    "    fig_pairplot = sns.pairplot(df, hue=\"class\", palette=\"deep\")\n",
    "    fig_pairplot.savefig('pairplot_merged.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffb4f72-87b7-48e4-a334-0686d6bc7f16",
   "metadata": {},
   "source": [
    "**Merged Pairplot**: questo ha un'ulteriore utilità pké nonostante io abbia verificato che nn ci sono dipendenze evidenti separatamente tra le features, potenzialmente potrebbero esserci modi semplici di classificare sla base di poche feature (magari lo scatter tra 2 feature separa nettamente le 2 classi e quindi il problema di classificazione è immediatamente risolto). Effettivamente nn sembrano esserci maniere evidenti di risolvere il problema di classificazione a mano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d8476-f152-417c-8a12-17aa9451a19a",
   "metadata": {},
   "source": [
    "## Dataframes to *train&test* the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31b66a39-93ee-4a14-b32f-28e9b4b0ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary features\n",
    "df.drop(['iso','Q'], inplace=True, axis=1)\n",
    "\n",
    "# map class to int\n",
    "df['class'] = df['class'].map({'enu': 0, 'munu': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a282a896-f145-4a28-bde9-06aca269a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels from data\n",
    "X = df.drop(['class'], axis=1)\n",
    "y = df['class']\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75af9d03-1ad7-4546-888c-f2c8f0055b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0) # this outputs pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddafc2e2-303e-4bb4-989c-4906220b7890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pt</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>MET</th>\n",
       "      <th>phiMET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80623</th>\n",
       "      <td>64.0320</td>\n",
       "      <td>2.1130</td>\n",
       "      <td>2.6280</td>\n",
       "      <td>18.8360</td>\n",
       "      <td>-0.3797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25980</th>\n",
       "      <td>53.6347</td>\n",
       "      <td>1.2090</td>\n",
       "      <td>1.7389</td>\n",
       "      <td>18.7289</td>\n",
       "      <td>1.7811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88459</th>\n",
       "      <td>46.9111</td>\n",
       "      <td>2.2845</td>\n",
       "      <td>2.1415</td>\n",
       "      <td>15.4821</td>\n",
       "      <td>-0.0468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129340</th>\n",
       "      <td>40.0649</td>\n",
       "      <td>-1.4004</td>\n",
       "      <td>-3.1235</td>\n",
       "      <td>22.4505</td>\n",
       "      <td>-1.7030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171820</th>\n",
       "      <td>42.5995</td>\n",
       "      <td>-0.4345</td>\n",
       "      <td>-1.6350</td>\n",
       "      <td>34.9186</td>\n",
       "      <td>0.9710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pt     eta     phi      MET  phiMET\n",
       "80623   64.0320  2.1130  2.6280  18.8360 -0.3797\n",
       "25980   53.6347  1.2090  1.7389  18.7289  1.7811\n",
       "88459   46.9111  2.2845  2.1415  15.4821 -0.0468\n",
       "129340  40.0649 -1.4004 -3.1235  22.4505 -1.7030\n",
       "171820  42.5995 -0.4345 -1.6350  34.9186  0.9710"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c46909-21b2-4e05-921b-2b3e997aa552",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c6cbbf1-9b95-4a95-8ae9-24122d658962",
   "metadata": {},
   "source": [
    "if preproc_log=='y':\n",
    "    X_train[\"log(pt)\"] = X_train['pt'].apply(np.log1p) # questa roba qua fa ln(1 + x) -> credo sia solo per prendere le distanze dla potenziale divergenza in 0\n",
    "    X_train[\"log(MET)\"] = X_train['MET'].apply(np.log1p) \n",
    "    \n",
    "    X_train.drop(['pt','MET'], inplace=True, axis=1)\n",
    "    X_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07850830-00be-48f4-9220-75e72827d818",
   "metadata": {},
   "source": [
    "**Standardizzazione** (0 mean and variance 1, but it's still a linear transformation, I'm not forcing the data to be normal!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00ba9d71",
   "metadata": {
    "id": "HbT55arOzMQN",
    "papermill": {
     "duration": 1.175011,
     "end_time": "2023-02-17T08:59:11.851595",
     "exception": false,
     "start_time": "2023-02-17T08:59:10.676584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Costruiamo il layer e informiamolo (ie ho solo 1 forma/STRUTTURA che adatto ai dati MA NN LO STO POPOLANDO!)\n",
    "X_train_scaler = tf.keras.layers.Normalization(axis=-1) # axis=-1 gli dice come leggere il tensor ie in quale direz calcolare medie e varianze (qua banalmente se sle righe (axis=0) o sle colonne (axis=-1 o axis=1 fa li stès))\n",
    "X_train_scaler.adapt(tf.convert_to_tensor(X_train)) # qua informiamo il layer sui dati, ie si calcola medie e varianze che userà poi\n",
    "\n",
    "X_test_scaler = tf.keras.layers.Normalization(axis=-1)\n",
    "X_test_scaler.adapt(tf.convert_to_tensor(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fda28e-c3d5-4326-9cce-1276cfd7c463",
   "metadata": {},
   "source": [
    "# Building and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0b68cda-953f-4139-9c2d-522abc2c2693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def my_model():\n",
    "   model = tf.keras.Sequential([\n",
    "    X_train_scaler,\n",
    "    tf.keras.layers.Dense(28, activation=activation),\n",
    "    tf.keras.layers.Dense(12, activation=activation),\n",
    "  # tf.keras.layers.Dense(6, activation=activation),\n",
    "    tf.keras.layers.Dense(12, activation=activation),\n",
    "    tf.keras.layers.Dense(28, activation=activation),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)       \n",
    "   ])\n",
    "   model.compile(\n",
    "                 optimizer=choosen_optimizer,\n",
    "       # usiamo \"Sparse\" perché le classes nn sono rappresentate con one hot encoding ie (0,1) e (1,0) ma con interi ie 0 e 1\n",
    "                 loss = choosen_loss,\n",
    "                 metrics=['accuracy'])\n",
    " \n",
    "   return model\n",
    "\n",
    "model = my_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906cace-a30f-4cc2-b2d2-c47e1d08fb57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - accuracy: 0.5723 - loss: 0.6720 - val_accuracy: 0.6625 - val_loss: 0.5912\n",
      "Epoch 2/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.6666 - loss: 0.5899 - val_accuracy: 0.6658 - val_loss: 0.5883\n",
      "Epoch 3/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.6660 - loss: 0.5881 - val_accuracy: 0.6696 - val_loss: 0.5852\n",
      "Epoch 4/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.6717 - loss: 0.5829 - val_accuracy: 0.6814 - val_loss: 0.5745\n",
      "Epoch 5/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.6884 - loss: 0.5664 - val_accuracy: 0.7357 - val_loss: 0.5271\n",
      "Epoch 6/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.7468 - loss: 0.5111 - val_accuracy: 0.7565 - val_loss: 0.5027\n",
      "Epoch 7/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - accuracy: 0.7534 - loss: 0.4958 - val_accuracy: 0.7577 - val_loss: 0.4914\n",
      "Epoch 8/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - accuracy: 0.7562 - loss: 0.4901 - val_accuracy: 0.7388 - val_loss: 0.5054\n",
      "Epoch 9/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.7581 - loss: 0.4864 - val_accuracy: 0.7586 - val_loss: 0.4852\n",
      "Epoch 10/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - accuracy: 0.7595 - loss: 0.4835 - val_accuracy: 0.7589 - val_loss: 0.4829\n",
      "Epoch 11/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - accuracy: 0.7598 - loss: 0.4817 - val_accuracy: 0.7632 - val_loss: 0.4783\n",
      "Epoch 12/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.7606 - loss: 0.4798 - val_accuracy: 0.7637 - val_loss: 0.4784\n",
      "Epoch 13/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.7615 - loss: 0.4777 - val_accuracy: 0.7651 - val_loss: 0.4759\n",
      "Epoch 14/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - accuracy: 0.7628 - loss: 0.4742 - val_accuracy: 0.7621 - val_loss: 0.4743\n",
      "Epoch 15/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.7654 - loss: 0.4699 - val_accuracy: 0.7653 - val_loss: 0.4704\n",
      "Epoch 16/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.7641 - loss: 0.4698 - val_accuracy: 0.7660 - val_loss: 0.4700\n",
      "Epoch 17/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7627 - loss: 0.4708 - val_accuracy: 0.7652 - val_loss: 0.4678\n",
      "Epoch 18/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.7637 - loss: 0.4676 - val_accuracy: 0.7648 - val_loss: 0.4679\n",
      "Epoch 19/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7636 - loss: 0.4681 - val_accuracy: 0.7659 - val_loss: 0.4658\n",
      "Epoch 20/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.7648 - loss: 0.4667 - val_accuracy: 0.7652 - val_loss: 0.4658\n",
      "Epoch 21/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.7660 - loss: 0.4630 - val_accuracy: 0.7647 - val_loss: 0.4642\n",
      "Epoch 22/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.7648 - loss: 0.4649 - val_accuracy: 0.7663 - val_loss: 0.4638\n",
      "Epoch 23/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7648 - loss: 0.4646 - val_accuracy: 0.7668 - val_loss: 0.4630\n",
      "Epoch 24/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.7639 - loss: 0.4640 - val_accuracy: 0.7657 - val_loss: 0.4628\n",
      "Epoch 25/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.7672 - loss: 0.4625 - val_accuracy: 0.7667 - val_loss: 0.4617\n",
      "Epoch 26/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7658 - loss: 0.4627 - val_accuracy: 0.7662 - val_loss: 0.4629\n",
      "Epoch 27/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.7645 - loss: 0.4638 - val_accuracy: 0.7671 - val_loss: 0.4607\n",
      "Epoch 28/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - accuracy: 0.7657 - loss: 0.4628 - val_accuracy: 0.7665 - val_loss: 0.4607\n",
      "Epoch 29/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7651 - loss: 0.4629 - val_accuracy: 0.7658 - val_loss: 0.4637\n",
      "Epoch 30/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.7642 - loss: 0.4615 - val_accuracy: 0.7668 - val_loss: 0.4615\n",
      "Epoch 31/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - accuracy: 0.7673 - loss: 0.4595 - val_accuracy: 0.7673 - val_loss: 0.4600\n",
      "Epoch 32/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7657 - loss: 0.4604 - val_accuracy: 0.7672 - val_loss: 0.4592\n",
      "Epoch 33/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.7653 - loss: 0.4606 - val_accuracy: 0.7675 - val_loss: 0.4598\n",
      "Epoch 34/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.7657 - loss: 0.4599 - val_accuracy: 0.7670 - val_loss: 0.4592\n",
      "Epoch 35/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.7673 - loss: 0.4586 - val_accuracy: 0.7666 - val_loss: 0.4592\n",
      "Epoch 36/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - accuracy: 0.7654 - loss: 0.4593 - val_accuracy: 0.7663 - val_loss: 0.4597\n",
      "Epoch 37/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.7671 - loss: 0.4580 - val_accuracy: 0.7676 - val_loss: 0.4581\n",
      "Epoch 38/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.7667 - loss: 0.4577 - val_accuracy: 0.7670 - val_loss: 0.4589\n",
      "Epoch 39/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.7671 - loss: 0.4588 - val_accuracy: 0.7658 - val_loss: 0.4598\n",
      "Epoch 40/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.7652 - loss: 0.4596 - val_accuracy: 0.7677 - val_loss: 0.4577\n",
      "Epoch 41/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.7658 - loss: 0.4585 - val_accuracy: 0.7676 - val_loss: 0.4579\n",
      "Epoch 42/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.7687 - loss: 0.4557 - val_accuracy: 0.7683 - val_loss: 0.4571\n",
      "Epoch 43/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7646 - loss: 0.4583 - val_accuracy: 0.7694 - val_loss: 0.4570\n",
      "Epoch 44/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7689 - loss: 0.4550 - val_accuracy: 0.7686 - val_loss: 0.4586\n",
      "Epoch 45/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.7685 - loss: 0.4548 - val_accuracy: 0.7691 - val_loss: 0.4564\n",
      "Epoch 46/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7663 - loss: 0.4572 - val_accuracy: 0.7688 - val_loss: 0.4559\n",
      "Epoch 47/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.7662 - loss: 0.4572 - val_accuracy: 0.7699 - val_loss: 0.4573\n",
      "Epoch 48/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.7675 - loss: 0.4551 - val_accuracy: 0.7686 - val_loss: 0.4557\n",
      "Epoch 49/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7657 - loss: 0.4573 - val_accuracy: 0.7694 - val_loss: 0.4562\n",
      "Epoch 50/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.7670 - loss: 0.4569 - val_accuracy: 0.7674 - val_loss: 0.4587\n",
      "Epoch 51/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.7670 - loss: 0.4549 - val_accuracy: 0.7692 - val_loss: 0.4572\n",
      "Epoch 52/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.7651 - loss: 0.4571 - val_accuracy: 0.7692 - val_loss: 0.4542\n",
      "Epoch 53/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554us/step - accuracy: 0.7666 - loss: 0.4559 - val_accuracy: 0.7694 - val_loss: 0.4552\n",
      "Epoch 54/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.7670 - loss: 0.4549 - val_accuracy: 0.7703 - val_loss: 0.4562\n",
      "Epoch 55/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.7651 - loss: 0.4553 - val_accuracy: 0.7688 - val_loss: 0.4564\n",
      "Epoch 56/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.7703 - loss: 0.4525 - val_accuracy: 0.7675 - val_loss: 0.4553\n",
      "Epoch 57/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7687 - loss: 0.4529 - val_accuracy: 0.7701 - val_loss: 0.4546\n",
      "Epoch 58/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7678 - loss: 0.4524 - val_accuracy: 0.7702 - val_loss: 0.4543\n",
      "Epoch 59/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.7666 - loss: 0.4539 - val_accuracy: 0.7706 - val_loss: 0.4528\n",
      "Epoch 60/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.7661 - loss: 0.4546 - val_accuracy: 0.7704 - val_loss: 0.4527\n",
      "Epoch 61/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.7692 - loss: 0.4521 - val_accuracy: 0.7709 - val_loss: 0.4535\n",
      "Epoch 62/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.7699 - loss: 0.4509 - val_accuracy: 0.7675 - val_loss: 0.4591\n",
      "Epoch 63/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7688 - loss: 0.4513 - val_accuracy: 0.7709 - val_loss: 0.4517\n",
      "Epoch 64/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.7672 - loss: 0.4524 - val_accuracy: 0.7698 - val_loss: 0.4539\n",
      "Epoch 65/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7665 - loss: 0.4528 - val_accuracy: 0.7702 - val_loss: 0.4526\n",
      "Epoch 66/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.7673 - loss: 0.4523 - val_accuracy: 0.7690 - val_loss: 0.4526\n",
      "Epoch 67/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.7684 - loss: 0.4517 - val_accuracy: 0.7701 - val_loss: 0.4517\n",
      "Epoch 68/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.7697 - loss: 0.4508 - val_accuracy: 0.7703 - val_loss: 0.4512\n",
      "Epoch 69/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.7695 - loss: 0.4505 - val_accuracy: 0.7702 - val_loss: 0.4517\n",
      "Epoch 70/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7680 - loss: 0.4514 - val_accuracy: 0.7701 - val_loss: 0.4517\n",
      "Epoch 71/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.7683 - loss: 0.4514 - val_accuracy: 0.7703 - val_loss: 0.4503\n",
      "Epoch 72/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7705 - loss: 0.4491 - val_accuracy: 0.7697 - val_loss: 0.4507\n",
      "Epoch 73/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.7685 - loss: 0.4515 - val_accuracy: 0.7705 - val_loss: 0.4517\n",
      "Epoch 74/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7677 - loss: 0.4517 - val_accuracy: 0.7683 - val_loss: 0.4540\n",
      "Epoch 75/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7685 - loss: 0.4507 - val_accuracy: 0.7701 - val_loss: 0.4505\n",
      "Epoch 76/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.7687 - loss: 0.4497 - val_accuracy: 0.7700 - val_loss: 0.4498\n",
      "Epoch 77/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7705 - loss: 0.4481 - val_accuracy: 0.7691 - val_loss: 0.4510\n",
      "Epoch 78/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7702 - loss: 0.4490 - val_accuracy: 0.7690 - val_loss: 0.4524\n",
      "Epoch 79/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7700 - loss: 0.4492 - val_accuracy: 0.7706 - val_loss: 0.4490\n",
      "Epoch 80/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7691 - loss: 0.4498 - val_accuracy: 0.7703 - val_loss: 0.4500\n",
      "Epoch 81/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7692 - loss: 0.4485 - val_accuracy: 0.7702 - val_loss: 0.4500\n",
      "Epoch 82/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7701 - loss: 0.4477 - val_accuracy: 0.7700 - val_loss: 0.4505\n",
      "Epoch 83/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7672 - loss: 0.4501 - val_accuracy: 0.7695 - val_loss: 0.4513\n",
      "Epoch 84/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.7672 - loss: 0.4481 - val_accuracy: 0.7697 - val_loss: 0.4482\n",
      "Epoch 85/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7679 - loss: 0.4474 - val_accuracy: 0.7701 - val_loss: 0.4496\n",
      "Epoch 86/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7671 - loss: 0.4497 - val_accuracy: 0.7696 - val_loss: 0.4505\n",
      "Epoch 87/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7708 - loss: 0.4478 - val_accuracy: 0.7688 - val_loss: 0.4527\n",
      "Epoch 88/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7702 - loss: 0.4460 - val_accuracy: 0.7699 - val_loss: 0.4487\n",
      "Epoch 89/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7715 - loss: 0.4464 - val_accuracy: 0.7705 - val_loss: 0.4493\n",
      "Epoch 90/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7698 - loss: 0.4455 - val_accuracy: 0.7699 - val_loss: 0.4486\n",
      "Epoch 91/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7688 - loss: 0.4473 - val_accuracy: 0.7695 - val_loss: 0.4509\n",
      "Epoch 92/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7693 - loss: 0.4478 - val_accuracy: 0.7705 - val_loss: 0.4471\n",
      "Epoch 93/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7686 - loss: 0.4463 - val_accuracy: 0.7709 - val_loss: 0.4464\n",
      "Epoch 94/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7673 - loss: 0.4488 - val_accuracy: 0.7709 - val_loss: 0.4473\n",
      "Epoch 95/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7677 - loss: 0.4486 - val_accuracy: 0.7706 - val_loss: 0.4467\n",
      "Epoch 96/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7698 - loss: 0.4456 - val_accuracy: 0.7701 - val_loss: 0.4459\n",
      "Epoch 97/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7700 - loss: 0.4468 - val_accuracy: 0.7670 - val_loss: 0.4525\n",
      "Epoch 98/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7689 - loss: 0.4472 - val_accuracy: 0.7701 - val_loss: 0.4455\n",
      "Epoch 99/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7700 - loss: 0.4452 - val_accuracy: 0.7671 - val_loss: 0.4539\n",
      "Epoch 100/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7678 - loss: 0.4483 - val_accuracy: 0.7689 - val_loss: 0.4484\n",
      "Epoch 101/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7675 - loss: 0.4457 - val_accuracy: 0.7697 - val_loss: 0.4480\n",
      "Epoch 102/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.7684 - loss: 0.4467 - val_accuracy: 0.7702 - val_loss: 0.4463\n",
      "Epoch 103/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7692 - loss: 0.4461 - val_accuracy: 0.7703 - val_loss: 0.4452\n",
      "Epoch 104/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7676 - loss: 0.4473 - val_accuracy: 0.7702 - val_loss: 0.4454\n",
      "Epoch 105/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7678 - loss: 0.4468 - val_accuracy: 0.7707 - val_loss: 0.4458\n",
      "Epoch 106/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7661 - loss: 0.4478 - val_accuracy: 0.7698 - val_loss: 0.4473\n",
      "Epoch 107/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.7698 - loss: 0.4451 - val_accuracy: 0.7695 - val_loss: 0.4462\n",
      "Epoch 108/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - accuracy: 0.7671 - loss: 0.4466 - val_accuracy: 0.7714 - val_loss: 0.4453\n",
      "Epoch 109/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7686 - loss: 0.4455 - val_accuracy: 0.7699 - val_loss: 0.4440\n",
      "Epoch 110/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7684 - loss: 0.4451 - val_accuracy: 0.7704 - val_loss: 0.4444\n",
      "Epoch 111/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7689 - loss: 0.4453 - val_accuracy: 0.7703 - val_loss: 0.4450\n",
      "Epoch 112/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7673 - loss: 0.4469 - val_accuracy: 0.7694 - val_loss: 0.4470\n",
      "Epoch 113/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7690 - loss: 0.4457 - val_accuracy: 0.7681 - val_loss: 0.4465\n",
      "Epoch 114/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.7705 - loss: 0.4436 - val_accuracy: 0.7703 - val_loss: 0.4452\n",
      "Epoch 115/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7691 - loss: 0.4442 - val_accuracy: 0.7685 - val_loss: 0.4456\n",
      "Epoch 116/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7678 - loss: 0.4463 - val_accuracy: 0.7707 - val_loss: 0.4435\n",
      "Epoch 117/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7698 - loss: 0.4429 - val_accuracy: 0.7637 - val_loss: 0.4555\n",
      "Epoch 118/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7705 - loss: 0.4425 - val_accuracy: 0.7699 - val_loss: 0.4440\n",
      "Epoch 119/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7689 - loss: 0.4444 - val_accuracy: 0.7701 - val_loss: 0.4438\n",
      "Epoch 120/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7687 - loss: 0.4444 - val_accuracy: 0.7712 - val_loss: 0.4436\n",
      "Epoch 121/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7687 - loss: 0.4443 - val_accuracy: 0.7668 - val_loss: 0.4466\n",
      "Epoch 122/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7704 - loss: 0.4427 - val_accuracy: 0.7700 - val_loss: 0.4453\n",
      "Epoch 123/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7686 - loss: 0.4452 - val_accuracy: 0.7704 - val_loss: 0.4458\n",
      "Epoch 124/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7701 - loss: 0.4429 - val_accuracy: 0.7702 - val_loss: 0.4426\n",
      "Epoch 125/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7701 - loss: 0.4423 - val_accuracy: 0.7674 - val_loss: 0.4464\n",
      "Epoch 126/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7689 - loss: 0.4448 - val_accuracy: 0.7695 - val_loss: 0.4435\n",
      "Epoch 127/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7693 - loss: 0.4446 - val_accuracy: 0.7707 - val_loss: 0.4442\n",
      "Epoch 128/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7678 - loss: 0.4446 - val_accuracy: 0.7683 - val_loss: 0.4449\n",
      "Epoch 129/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7683 - loss: 0.4438 - val_accuracy: 0.7713 - val_loss: 0.4416\n",
      "Epoch 130/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7695 - loss: 0.4431 - val_accuracy: 0.7707 - val_loss: 0.4427\n",
      "Epoch 131/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - accuracy: 0.7710 - loss: 0.4421 - val_accuracy: 0.7712 - val_loss: 0.4430\n",
      "Epoch 132/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7704 - loss: 0.4423 - val_accuracy: 0.7689 - val_loss: 0.4460\n",
      "Epoch 133/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7682 - loss: 0.4439 - val_accuracy: 0.7707 - val_loss: 0.4441\n",
      "Epoch 134/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7675 - loss: 0.4448 - val_accuracy: 0.7689 - val_loss: 0.4433\n",
      "Epoch 135/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7700 - loss: 0.4419 - val_accuracy: 0.7718 - val_loss: 0.4423\n",
      "Epoch 136/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7684 - loss: 0.4423 - val_accuracy: 0.7716 - val_loss: 0.4419\n",
      "Epoch 137/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7700 - loss: 0.4421 - val_accuracy: 0.7679 - val_loss: 0.4441\n",
      "Epoch 138/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7704 - loss: 0.4416 - val_accuracy: 0.7697 - val_loss: 0.4442\n",
      "Epoch 139/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7688 - loss: 0.4443 - val_accuracy: 0.7708 - val_loss: 0.4416\n",
      "Epoch 140/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7718 - loss: 0.4408 - val_accuracy: 0.7689 - val_loss: 0.4437\n",
      "Epoch 141/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7693 - loss: 0.4424 - val_accuracy: 0.7695 - val_loss: 0.4435\n",
      "Epoch 142/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7706 - loss: 0.4413 - val_accuracy: 0.7703 - val_loss: 0.4412\n",
      "Epoch 143/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7720 - loss: 0.4389 - val_accuracy: 0.7679 - val_loss: 0.4437\n",
      "Epoch 144/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7702 - loss: 0.4429 - val_accuracy: 0.7710 - val_loss: 0.4435\n",
      "Epoch 145/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.7705 - loss: 0.4420 - val_accuracy: 0.7708 - val_loss: 0.4407\n",
      "Epoch 146/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7695 - loss: 0.4421 - val_accuracy: 0.7705 - val_loss: 0.4418\n",
      "Epoch 147/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7702 - loss: 0.4419 - val_accuracy: 0.7717 - val_loss: 0.4415\n",
      "Epoch 148/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7670 - loss: 0.4462 - val_accuracy: 0.7704 - val_loss: 0.4418\n",
      "Epoch 149/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7706 - loss: 0.4413 - val_accuracy: 0.7709 - val_loss: 0.4404\n",
      "Epoch 150/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7689 - loss: 0.4417 - val_accuracy: 0.7668 - val_loss: 0.4443\n",
      "Epoch 151/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7664 - loss: 0.4452 - val_accuracy: 0.7721 - val_loss: 0.4401\n",
      "Epoch 152/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.7671 - loss: 0.4443 - val_accuracy: 0.7712 - val_loss: 0.4400\n",
      "Epoch 153/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7727 - loss: 0.4402 - val_accuracy: 0.7721 - val_loss: 0.4420\n",
      "Epoch 154/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7692 - loss: 0.4429 - val_accuracy: 0.7678 - val_loss: 0.4443\n",
      "Epoch 155/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7698 - loss: 0.4407 - val_accuracy: 0.7699 - val_loss: 0.4413\n",
      "Epoch 156/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - accuracy: 0.7687 - loss: 0.4429 - val_accuracy: 0.7699 - val_loss: 0.4417\n",
      "Epoch 157/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.7706 - loss: 0.4416 - val_accuracy: 0.7709 - val_loss: 0.4400\n",
      "Epoch 158/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.7685 - loss: 0.4439 - val_accuracy: 0.7684 - val_loss: 0.4430\n",
      "Epoch 159/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.7695 - loss: 0.4429 - val_accuracy: 0.7693 - val_loss: 0.4431\n",
      "Epoch 160/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.7702 - loss: 0.4421 - val_accuracy: 0.7706 - val_loss: 0.4429\n",
      "Epoch 161/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.7695 - loss: 0.4415 - val_accuracy: 0.7696 - val_loss: 0.4410\n",
      "Epoch 162/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.7705 - loss: 0.4401 - val_accuracy: 0.7718 - val_loss: 0.4408\n",
      "Epoch 163/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7701 - loss: 0.4415 - val_accuracy: 0.7714 - val_loss: 0.4399\n",
      "Epoch 164/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7684 - loss: 0.4431 - val_accuracy: 0.7714 - val_loss: 0.4398\n",
      "Epoch 165/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7694 - loss: 0.4412 - val_accuracy: 0.7702 - val_loss: 0.4425\n",
      "Epoch 166/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7690 - loss: 0.4423 - val_accuracy: 0.7713 - val_loss: 0.4391\n",
      "Epoch 167/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7704 - loss: 0.4399 - val_accuracy: 0.7678 - val_loss: 0.4453\n",
      "Epoch 168/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7691 - loss: 0.4412 - val_accuracy: 0.7707 - val_loss: 0.4406\n",
      "Epoch 169/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7710 - loss: 0.4403 - val_accuracy: 0.7717 - val_loss: 0.4396\n",
      "Epoch 170/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7719 - loss: 0.4392 - val_accuracy: 0.7727 - val_loss: 0.4392\n",
      "Epoch 171/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7697 - loss: 0.4395 - val_accuracy: 0.7668 - val_loss: 0.4440\n",
      "Epoch 172/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7686 - loss: 0.4407 - val_accuracy: 0.7696 - val_loss: 0.4395\n",
      "Epoch 173/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7706 - loss: 0.4394 - val_accuracy: 0.7721 - val_loss: 0.4400\n",
      "Epoch 174/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7713 - loss: 0.4398 - val_accuracy: 0.7701 - val_loss: 0.4429\n",
      "Epoch 175/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7695 - loss: 0.4415 - val_accuracy: 0.7719 - val_loss: 0.4386\n",
      "Epoch 176/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7710 - loss: 0.4395 - val_accuracy: 0.7722 - val_loss: 0.4392\n",
      "Epoch 177/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7703 - loss: 0.4392 - val_accuracy: 0.7714 - val_loss: 0.4398\n",
      "Epoch 178/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7722 - loss: 0.4388 - val_accuracy: 0.7719 - val_loss: 0.4391\n",
      "Epoch 179/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.7724 - loss: 0.4377 - val_accuracy: 0.7697 - val_loss: 0.4415\n",
      "Epoch 180/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7717 - loss: 0.4397 - val_accuracy: 0.7722 - val_loss: 0.4386\n",
      "Epoch 181/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7725 - loss: 0.4378 - val_accuracy: 0.7720 - val_loss: 0.4392\n",
      "Epoch 182/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7696 - loss: 0.4394 - val_accuracy: 0.7690 - val_loss: 0.4397\n",
      "Epoch 183/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7726 - loss: 0.4378 - val_accuracy: 0.7703 - val_loss: 0.4406\n",
      "Epoch 184/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7711 - loss: 0.4386 - val_accuracy: 0.7678 - val_loss: 0.4429\n",
      "Epoch 185/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7710 - loss: 0.4392 - val_accuracy: 0.7675 - val_loss: 0.4426\n",
      "Epoch 186/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - accuracy: 0.7703 - loss: 0.4401 - val_accuracy: 0.7718 - val_loss: 0.4383\n",
      "Epoch 187/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7689 - loss: 0.4399 - val_accuracy: 0.7714 - val_loss: 0.4388\n",
      "Epoch 188/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7683 - loss: 0.4411 - val_accuracy: 0.7724 - val_loss: 0.4390\n",
      "Epoch 189/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.7720 - loss: 0.4387 - val_accuracy: 0.7710 - val_loss: 0.4386\n",
      "Epoch 190/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7696 - loss: 0.4392 - val_accuracy: 0.7724 - val_loss: 0.4385\n",
      "Epoch 191/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.7697 - loss: 0.4404 - val_accuracy: 0.7725 - val_loss: 0.4411\n",
      "Epoch 192/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.7699 - loss: 0.4406 - val_accuracy: 0.7694 - val_loss: 0.4395\n",
      "Epoch 193/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7713 - loss: 0.4379 - val_accuracy: 0.7707 - val_loss: 0.4385\n",
      "Epoch 194/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584us/step - accuracy: 0.7696 - loss: 0.4395 - val_accuracy: 0.7703 - val_loss: 0.4403\n",
      "Epoch 195/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.7708 - loss: 0.4393 - val_accuracy: 0.7715 - val_loss: 0.4381\n",
      "Epoch 196/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7706 - loss: 0.4395 - val_accuracy: 0.7731 - val_loss: 0.4388\n",
      "Epoch 197/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7704 - loss: 0.4396 - val_accuracy: 0.7720 - val_loss: 0.4385\n",
      "Epoch 198/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7712 - loss: 0.4382 - val_accuracy: 0.7722 - val_loss: 0.4383\n",
      "Epoch 199/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - accuracy: 0.7708 - loss: 0.4385 - val_accuracy: 0.7721 - val_loss: 0.4376\n",
      "Epoch 200/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.7712 - loss: 0.4377 - val_accuracy: 0.7697 - val_loss: 0.4400\n",
      "Epoch 201/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7740 - loss: 0.4360 - val_accuracy: 0.7723 - val_loss: 0.4382\n",
      "Epoch 202/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591us/step - accuracy: 0.7714 - loss: 0.4373 - val_accuracy: 0.7692 - val_loss: 0.4391\n",
      "Epoch 203/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - accuracy: 0.7728 - loss: 0.4370 - val_accuracy: 0.7658 - val_loss: 0.4433\n",
      "Epoch 204/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - accuracy: 0.7690 - loss: 0.4406 - val_accuracy: 0.7711 - val_loss: 0.4393\n",
      "Epoch 205/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7711 - loss: 0.4380 - val_accuracy: 0.7691 - val_loss: 0.4398\n",
      "Epoch 206/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7708 - loss: 0.4385 - val_accuracy: 0.7727 - val_loss: 0.4385\n",
      "Epoch 207/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7695 - loss: 0.4396 - val_accuracy: 0.7703 - val_loss: 0.4412\n",
      "Epoch 208/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7697 - loss: 0.4401 - val_accuracy: 0.7725 - val_loss: 0.4380\n",
      "Epoch 209/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7698 - loss: 0.4382 - val_accuracy: 0.7709 - val_loss: 0.4394\n",
      "Epoch 210/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7706 - loss: 0.4393 - val_accuracy: 0.7699 - val_loss: 0.4393\n",
      "Epoch 211/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7703 - loss: 0.4389 - val_accuracy: 0.7723 - val_loss: 0.4407\n",
      "Epoch 212/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7709 - loss: 0.4392 - val_accuracy: 0.7698 - val_loss: 0.4382\n",
      "Epoch 213/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7711 - loss: 0.4390 - val_accuracy: 0.7705 - val_loss: 0.4407\n",
      "Epoch 214/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7685 - loss: 0.4407 - val_accuracy: 0.7718 - val_loss: 0.4380\n",
      "Epoch 215/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7710 - loss: 0.4377 - val_accuracy: 0.7697 - val_loss: 0.4433\n",
      "Epoch 216/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7686 - loss: 0.4386 - val_accuracy: 0.7720 - val_loss: 0.4374\n",
      "Epoch 217/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7690 - loss: 0.4399 - val_accuracy: 0.7726 - val_loss: 0.4382\n",
      "Epoch 218/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.7727 - loss: 0.4374 - val_accuracy: 0.7697 - val_loss: 0.4400\n",
      "Epoch 219/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7718 - loss: 0.4391 - val_accuracy: 0.7694 - val_loss: 0.4389\n",
      "Epoch 220/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.7702 - loss: 0.4382 - val_accuracy: 0.7712 - val_loss: 0.4378\n",
      "Epoch 221/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7707 - loss: 0.4378 - val_accuracy: 0.7730 - val_loss: 0.4391\n",
      "Epoch 222/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.7718 - loss: 0.4383 - val_accuracy: 0.7718 - val_loss: 0.4385\n",
      "Epoch 223/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7726 - loss: 0.4357 - val_accuracy: 0.7682 - val_loss: 0.4426\n",
      "Epoch 224/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7725 - loss: 0.4371 - val_accuracy: 0.7716 - val_loss: 0.4390\n",
      "Epoch 225/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7695 - loss: 0.4398 - val_accuracy: 0.7716 - val_loss: 0.4379\n",
      "Epoch 226/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7702 - loss: 0.4380 - val_accuracy: 0.7693 - val_loss: 0.4394\n",
      "Epoch 227/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7688 - loss: 0.4407 - val_accuracy: 0.7700 - val_loss: 0.4390\n",
      "Epoch 228/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7709 - loss: 0.4387 - val_accuracy: 0.7725 - val_loss: 0.4387\n",
      "Epoch 229/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7704 - loss: 0.4379 - val_accuracy: 0.7715 - val_loss: 0.4389\n",
      "Epoch 230/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7702 - loss: 0.4392 - val_accuracy: 0.7706 - val_loss: 0.4392\n",
      "Epoch 231/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7730 - loss: 0.4375 - val_accuracy: 0.7711 - val_loss: 0.4380\n",
      "Epoch 232/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7696 - loss: 0.4386 - val_accuracy: 0.7693 - val_loss: 0.4407\n",
      "Epoch 233/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7716 - loss: 0.4364 - val_accuracy: 0.7715 - val_loss: 0.4381\n",
      "Epoch 234/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7712 - loss: 0.4381 - val_accuracy: 0.7722 - val_loss: 0.4377\n",
      "Epoch 235/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7717 - loss: 0.4376 - val_accuracy: 0.7722 - val_loss: 0.4393\n",
      "Epoch 236/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7723 - loss: 0.4371 - val_accuracy: 0.7715 - val_loss: 0.4397\n",
      "Epoch 237/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7708 - loss: 0.4386 - val_accuracy: 0.7715 - val_loss: 0.4426\n",
      "Epoch 238/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7724 - loss: 0.4370 - val_accuracy: 0.7689 - val_loss: 0.4412\n",
      "Epoch 239/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7705 - loss: 0.4384 - val_accuracy: 0.7722 - val_loss: 0.4381\n",
      "Epoch 240/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.7741 - loss: 0.4365 - val_accuracy: 0.7708 - val_loss: 0.4385\n",
      "Epoch 241/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7703 - loss: 0.4384 - val_accuracy: 0.7715 - val_loss: 0.4400\n",
      "Epoch 242/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7711 - loss: 0.4370 - val_accuracy: 0.7714 - val_loss: 0.4383\n",
      "Epoch 243/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.7704 - loss: 0.4381 - val_accuracy: 0.7718 - val_loss: 0.4378\n",
      "Epoch 244/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.7709 - loss: 0.4388 - val_accuracy: 0.7720 - val_loss: 0.4397\n",
      "Epoch 245/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.7688 - loss: 0.4407 - val_accuracy: 0.7716 - val_loss: 0.4399\n",
      "Epoch 246/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7729 - loss: 0.4362 - val_accuracy: 0.7709 - val_loss: 0.4384\n",
      "Epoch 247/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7702 - loss: 0.4381 - val_accuracy: 0.7717 - val_loss: 0.4377\n",
      "Epoch 248/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7701 - loss: 0.4379 - val_accuracy: 0.7731 - val_loss: 0.4377\n",
      "Epoch 249/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7710 - loss: 0.4388 - val_accuracy: 0.7718 - val_loss: 0.4384\n",
      "Epoch 250/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - accuracy: 0.7733 - loss: 0.4363 - val_accuracy: 0.7718 - val_loss: 0.4376\n",
      "Epoch 251/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - accuracy: 0.7712 - loss: 0.4378 - val_accuracy: 0.7726 - val_loss: 0.4396\n",
      "Epoch 252/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.7720 - loss: 0.4366 - val_accuracy: 0.7711 - val_loss: 0.4385\n",
      "Epoch 253/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.7706 - loss: 0.4390 - val_accuracy: 0.7713 - val_loss: 0.4444\n",
      "Epoch 254/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.7699 - loss: 0.4385 - val_accuracy: 0.7712 - val_loss: 0.4389\n",
      "Epoch 255/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - accuracy: 0.7717 - loss: 0.4371 - val_accuracy: 0.7717 - val_loss: 0.4378\n",
      "Epoch 256/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - accuracy: 0.7698 - loss: 0.4406 - val_accuracy: 0.7720 - val_loss: 0.4375\n",
      "Epoch 257/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7706 - loss: 0.4385 - val_accuracy: 0.7710 - val_loss: 0.4385\n",
      "Epoch 258/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7710 - loss: 0.4399 - val_accuracy: 0.7719 - val_loss: 0.4381\n",
      "Epoch 259/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7708 - loss: 0.4384 - val_accuracy: 0.7721 - val_loss: 0.4381\n",
      "Epoch 260/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7725 - loss: 0.4374 - val_accuracy: 0.7688 - val_loss: 0.4420\n",
      "Epoch 261/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7731 - loss: 0.4369 - val_accuracy: 0.7700 - val_loss: 0.4391\n",
      "Epoch 262/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7726 - loss: 0.4369 - val_accuracy: 0.7716 - val_loss: 0.4386\n",
      "Epoch 263/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7721 - loss: 0.4374 - val_accuracy: 0.7725 - val_loss: 0.4375\n",
      "Epoch 264/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7712 - loss: 0.4386 - val_accuracy: 0.7695 - val_loss: 0.4403\n",
      "Epoch 265/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7716 - loss: 0.4375 - val_accuracy: 0.7720 - val_loss: 0.4383\n",
      "Epoch 266/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7725 - loss: 0.4361 - val_accuracy: 0.7725 - val_loss: 0.4397\n",
      "Epoch 267/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7721 - loss: 0.4380 - val_accuracy: 0.7709 - val_loss: 0.4403\n",
      "Epoch 268/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7719 - loss: 0.4387 - val_accuracy: 0.7726 - val_loss: 0.4376\n",
      "Epoch 269/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7697 - loss: 0.4398 - val_accuracy: 0.7729 - val_loss: 0.4383\n",
      "Epoch 270/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7705 - loss: 0.4387 - val_accuracy: 0.7712 - val_loss: 0.4391\n",
      "Epoch 271/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7719 - loss: 0.4386 - val_accuracy: 0.7725 - val_loss: 0.4424\n",
      "Epoch 272/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7715 - loss: 0.4379 - val_accuracy: 0.7718 - val_loss: 0.4386\n",
      "Epoch 273/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7690 - loss: 0.4394 - val_accuracy: 0.7728 - val_loss: 0.4383\n",
      "Epoch 274/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7710 - loss: 0.4382 - val_accuracy: 0.7728 - val_loss: 0.4399\n",
      "Epoch 275/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7717 - loss: 0.4385 - val_accuracy: 0.7707 - val_loss: 0.4397\n",
      "Epoch 276/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7719 - loss: 0.4392 - val_accuracy: 0.7714 - val_loss: 0.4392\n",
      "Epoch 277/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7692 - loss: 0.4401 - val_accuracy: 0.7719 - val_loss: 0.4384\n",
      "Epoch 278/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7698 - loss: 0.4393 - val_accuracy: 0.7707 - val_loss: 0.4424\n",
      "Epoch 279/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7719 - loss: 0.4384 - val_accuracy: 0.7726 - val_loss: 0.4397\n",
      "Epoch 280/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7709 - loss: 0.4400 - val_accuracy: 0.7709 - val_loss: 0.4394\n",
      "Epoch 281/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7712 - loss: 0.4383 - val_accuracy: 0.7725 - val_loss: 0.4405\n",
      "Epoch 282/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7706 - loss: 0.4394 - val_accuracy: 0.7707 - val_loss: 0.4399\n",
      "Epoch 283/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7694 - loss: 0.4400 - val_accuracy: 0.7695 - val_loss: 0.4418\n",
      "Epoch 284/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7705 - loss: 0.4390 - val_accuracy: 0.7726 - val_loss: 0.4416\n",
      "Epoch 285/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7708 - loss: 0.4407 - val_accuracy: 0.7738 - val_loss: 0.4383\n",
      "Epoch 286/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7704 - loss: 0.4384 - val_accuracy: 0.7732 - val_loss: 0.4386\n",
      "Epoch 287/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7718 - loss: 0.4378 - val_accuracy: 0.7722 - val_loss: 0.4396\n",
      "Epoch 288/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7713 - loss: 0.4380 - val_accuracy: 0.7733 - val_loss: 0.4398\n",
      "Epoch 289/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7699 - loss: 0.4392 - val_accuracy: 0.7736 - val_loss: 0.4384\n",
      "Epoch 290/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7711 - loss: 0.4373 - val_accuracy: 0.7703 - val_loss: 0.4408\n",
      "Epoch 291/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7702 - loss: 0.4384 - val_accuracy: 0.7693 - val_loss: 0.4401\n",
      "Epoch 292/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7709 - loss: 0.4389 - val_accuracy: 0.7731 - val_loss: 0.4381\n",
      "Epoch 293/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7706 - loss: 0.4379 - val_accuracy: 0.7714 - val_loss: 0.4389\n",
      "Epoch 294/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7698 - loss: 0.4403 - val_accuracy: 0.7672 - val_loss: 0.4445\n",
      "Epoch 295/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.7712 - loss: 0.4380 - val_accuracy: 0.7689 - val_loss: 0.4418\n",
      "Epoch 296/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7709 - loss: 0.4383 - val_accuracy: 0.7714 - val_loss: 0.4410\n",
      "Epoch 297/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7700 - loss: 0.4380 - val_accuracy: 0.7716 - val_loss: 0.4406\n",
      "Epoch 298/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7714 - loss: 0.4374 - val_accuracy: 0.7724 - val_loss: 0.4417\n",
      "Epoch 299/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7714 - loss: 0.4389 - val_accuracy: 0.7699 - val_loss: 0.4416\n",
      "Epoch 300/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7699 - loss: 0.4387 - val_accuracy: 0.7722 - val_loss: 0.4381\n",
      "Epoch 301/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7702 - loss: 0.4395 - val_accuracy: 0.7709 - val_loss: 0.4396\n",
      "Epoch 302/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7671 - loss: 0.4402 - val_accuracy: 0.7710 - val_loss: 0.4414\n",
      "Epoch 303/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7699 - loss: 0.4390 - val_accuracy: 0.7714 - val_loss: 0.4393\n",
      "Epoch 304/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7723 - loss: 0.4396 - val_accuracy: 0.7715 - val_loss: 0.4388\n",
      "Epoch 305/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7715 - loss: 0.4386 - val_accuracy: 0.7724 - val_loss: 0.4394\n",
      "Epoch 306/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7691 - loss: 0.4399 - val_accuracy: 0.7724 - val_loss: 0.4385\n",
      "Epoch 307/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7702 - loss: 0.4394 - val_accuracy: 0.7722 - val_loss: 0.4403\n",
      "Epoch 308/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7717 - loss: 0.4372 - val_accuracy: 0.7716 - val_loss: 0.4424\n",
      "Epoch 309/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7687 - loss: 0.4399 - val_accuracy: 0.7722 - val_loss: 0.4384\n",
      "Epoch 310/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7701 - loss: 0.4404 - val_accuracy: 0.7718 - val_loss: 0.4416\n",
      "Epoch 311/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7718 - loss: 0.4378 - val_accuracy: 0.7721 - val_loss: 0.4414\n",
      "Epoch 312/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7717 - loss: 0.4386 - val_accuracy: 0.7718 - val_loss: 0.4412\n",
      "Epoch 313/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7696 - loss: 0.4395 - val_accuracy: 0.7722 - val_loss: 0.4384\n",
      "Epoch 314/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7713 - loss: 0.4383 - val_accuracy: 0.7715 - val_loss: 0.4398\n",
      "Epoch 315/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7705 - loss: 0.4379 - val_accuracy: 0.7719 - val_loss: 0.4391\n",
      "Epoch 316/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7714 - loss: 0.4393 - val_accuracy: 0.7731 - val_loss: 0.4391\n",
      "Epoch 317/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7725 - loss: 0.4377 - val_accuracy: 0.7725 - val_loss: 0.4391\n",
      "Epoch 318/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7696 - loss: 0.4375 - val_accuracy: 0.7726 - val_loss: 0.4380\n",
      "Epoch 319/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7694 - loss: 0.4399 - val_accuracy: 0.7728 - val_loss: 0.4385\n",
      "Epoch 320/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7709 - loss: 0.4388 - val_accuracy: 0.7733 - val_loss: 0.4380\n",
      "Epoch 321/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7709 - loss: 0.4382 - val_accuracy: 0.7729 - val_loss: 0.4388\n",
      "Epoch 322/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7712 - loss: 0.4378 - val_accuracy: 0.7721 - val_loss: 0.4376\n",
      "Epoch 323/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.7724 - loss: 0.4374 - val_accuracy: 0.7713 - val_loss: 0.4397\n",
      "Epoch 324/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7718 - loss: 0.4379 - val_accuracy: 0.7724 - val_loss: 0.4383\n",
      "Epoch 325/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7705 - loss: 0.4382 - val_accuracy: 0.7727 - val_loss: 0.4382\n",
      "Epoch 326/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7714 - loss: 0.4385 - val_accuracy: 0.7718 - val_loss: 0.4397\n",
      "Epoch 327/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7711 - loss: 0.4372 - val_accuracy: 0.7718 - val_loss: 0.4383\n",
      "Epoch 328/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7718 - loss: 0.4367 - val_accuracy: 0.7722 - val_loss: 0.4384\n",
      "Epoch 329/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7697 - loss: 0.4383 - val_accuracy: 0.7718 - val_loss: 0.4387\n",
      "Epoch 330/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7725 - loss: 0.4365 - val_accuracy: 0.7731 - val_loss: 0.4381\n",
      "Epoch 331/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7694 - loss: 0.4388 - val_accuracy: 0.7721 - val_loss: 0.4380\n",
      "Epoch 332/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7689 - loss: 0.4395 - val_accuracy: 0.7712 - val_loss: 0.4392\n",
      "Epoch 333/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7708 - loss: 0.4391 - val_accuracy: 0.7729 - val_loss: 0.4383\n",
      "Epoch 334/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7698 - loss: 0.4399 - val_accuracy: 0.7728 - val_loss: 0.4389\n",
      "Epoch 335/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7720 - loss: 0.4372 - val_accuracy: 0.7710 - val_loss: 0.4383\n",
      "Epoch 336/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.7722 - loss: 0.4368 - val_accuracy: 0.7725 - val_loss: 0.4374\n",
      "Epoch 337/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7710 - loss: 0.4381 - val_accuracy: 0.7718 - val_loss: 0.4382\n",
      "Epoch 338/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7719 - loss: 0.4377 - val_accuracy: 0.7721 - val_loss: 0.4382\n",
      "Epoch 339/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.7714 - loss: 0.4369 - val_accuracy: 0.7718 - val_loss: 0.4379\n",
      "Epoch 340/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7708 - loss: 0.4382 - val_accuracy: 0.7716 - val_loss: 0.4392\n",
      "Epoch 341/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7714 - loss: 0.4381 - val_accuracy: 0.7719 - val_loss: 0.4372\n",
      "Epoch 342/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590us/step - accuracy: 0.7712 - loss: 0.4382 - val_accuracy: 0.7726 - val_loss: 0.4385\n",
      "Epoch 343/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591us/step - accuracy: 0.7700 - loss: 0.4386 - val_accuracy: 0.7709 - val_loss: 0.4447\n",
      "Epoch 344/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7696 - loss: 0.4393 - val_accuracy: 0.7732 - val_loss: 0.4378\n",
      "Epoch 345/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.7720 - loss: 0.4373 - val_accuracy: 0.7696 - val_loss: 0.4442\n",
      "Epoch 346/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7702 - loss: 0.4388 - val_accuracy: 0.7721 - val_loss: 0.4381\n",
      "Epoch 347/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.7719 - loss: 0.4368 - val_accuracy: 0.7723 - val_loss: 0.4382\n",
      "Epoch 348/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.7733 - loss: 0.4362 - val_accuracy: 0.7720 - val_loss: 0.4395\n",
      "Epoch 349/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.7708 - loss: 0.4388 - val_accuracy: 0.7713 - val_loss: 0.4434\n",
      "Epoch 350/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - accuracy: 0.7706 - loss: 0.4390 - val_accuracy: 0.7728 - val_loss: 0.4374\n",
      "Epoch 351/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.7706 - loss: 0.4379 - val_accuracy: 0.7723 - val_loss: 0.4376\n",
      "Epoch 352/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.7704 - loss: 0.4382 - val_accuracy: 0.7727 - val_loss: 0.4377\n",
      "Epoch 353/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - accuracy: 0.7698 - loss: 0.4398 - val_accuracy: 0.7718 - val_loss: 0.4379\n",
      "Epoch 354/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.7687 - loss: 0.4404 - val_accuracy: 0.7717 - val_loss: 0.4384\n",
      "Epoch 355/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.7713 - loss: 0.4369 - val_accuracy: 0.7720 - val_loss: 0.4383\n",
      "Epoch 356/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.7700 - loss: 0.4384 - val_accuracy: 0.7718 - val_loss: 0.4389\n",
      "Epoch 357/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590us/step - accuracy: 0.7710 - loss: 0.4379 - val_accuracy: 0.7725 - val_loss: 0.4372\n",
      "Epoch 358/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584us/step - accuracy: 0.7709 - loss: 0.4370 - val_accuracy: 0.7722 - val_loss: 0.4384\n",
      "Epoch 359/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7690 - loss: 0.4396 - val_accuracy: 0.7718 - val_loss: 0.4383\n",
      "Epoch 360/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584us/step - accuracy: 0.7693 - loss: 0.4400 - val_accuracy: 0.7710 - val_loss: 0.4417\n",
      "Epoch 361/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7714 - loss: 0.4372 - val_accuracy: 0.7716 - val_loss: 0.4380\n",
      "Epoch 362/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590us/step - accuracy: 0.7704 - loss: 0.4384 - val_accuracy: 0.7707 - val_loss: 0.4398\n",
      "Epoch 363/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7697 - loss: 0.4403 - val_accuracy: 0.7725 - val_loss: 0.4385\n",
      "Epoch 364/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step - accuracy: 0.7706 - loss: 0.4382 - val_accuracy: 0.7720 - val_loss: 0.4445\n",
      "Epoch 365/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.7701 - loss: 0.4377 - val_accuracy: 0.7729 - val_loss: 0.4366\n",
      "Epoch 366/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - accuracy: 0.7704 - loss: 0.4380 - val_accuracy: 0.7733 - val_loss: 0.4372\n",
      "Epoch 367/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590us/step - accuracy: 0.7709 - loss: 0.4385 - val_accuracy: 0.7716 - val_loss: 0.4373\n",
      "Epoch 368/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - accuracy: 0.7718 - loss: 0.4379 - val_accuracy: 0.7728 - val_loss: 0.4370\n",
      "Epoch 369/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - accuracy: 0.7696 - loss: 0.4393 - val_accuracy: 0.7719 - val_loss: 0.4389\n",
      "Epoch 370/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.7705 - loss: 0.4374 - val_accuracy: 0.7721 - val_loss: 0.4384\n",
      "Epoch 371/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 0.7707 - loss: 0.4393 - val_accuracy: 0.7720 - val_loss: 0.4383\n",
      "Epoch 372/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.7704 - loss: 0.4376 - val_accuracy: 0.7715 - val_loss: 0.4406\n",
      "Epoch 373/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.7710 - loss: 0.4372 - val_accuracy: 0.7720 - val_loss: 0.4373\n",
      "Epoch 374/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.7708 - loss: 0.4385 - val_accuracy: 0.7718 - val_loss: 0.4398\n",
      "Epoch 375/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - accuracy: 0.7706 - loss: 0.4362 - val_accuracy: 0.7726 - val_loss: 0.4384\n",
      "Epoch 376/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - accuracy: 0.7716 - loss: 0.4368 - val_accuracy: 0.7726 - val_loss: 0.4367\n",
      "Epoch 377/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - accuracy: 0.7697 - loss: 0.4401 - val_accuracy: 0.7719 - val_loss: 0.4362\n",
      "Epoch 378/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - accuracy: 0.7711 - loss: 0.4368 - val_accuracy: 0.7725 - val_loss: 0.4379\n",
      "Epoch 379/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.7720 - loss: 0.4356 - val_accuracy: 0.7725 - val_loss: 0.4388\n",
      "Epoch 380/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - accuracy: 0.7718 - loss: 0.4361 - val_accuracy: 0.7722 - val_loss: 0.4369\n",
      "Epoch 381/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.7718 - loss: 0.4372 - val_accuracy: 0.7719 - val_loss: 0.4390\n",
      "Epoch 382/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7710 - loss: 0.4369 - val_accuracy: 0.7717 - val_loss: 0.4404\n",
      "Epoch 383/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7718 - loss: 0.4371 - val_accuracy: 0.7723 - val_loss: 0.4369\n",
      "Epoch 384/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.7711 - loss: 0.4376 - val_accuracy: 0.7728 - val_loss: 0.4381\n",
      "Epoch 385/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - accuracy: 0.7713 - loss: 0.4369 - val_accuracy: 0.7728 - val_loss: 0.4381\n",
      "Epoch 386/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - accuracy: 0.7716 - loss: 0.4368 - val_accuracy: 0.7716 - val_loss: 0.4382\n",
      "Epoch 387/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.7701 - loss: 0.4386 - val_accuracy: 0.7727 - val_loss: 0.4381\n",
      "Epoch 388/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7704 - loss: 0.4371 - val_accuracy: 0.7704 - val_loss: 0.4420\n",
      "Epoch 389/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.7734 - loss: 0.4369 - val_accuracy: 0.7726 - val_loss: 0.4364\n",
      "Epoch 390/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - accuracy: 0.7712 - loss: 0.4373 - val_accuracy: 0.7724 - val_loss: 0.4376\n",
      "Epoch 391/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589us/step - accuracy: 0.7701 - loss: 0.4389 - val_accuracy: 0.7733 - val_loss: 0.4363\n",
      "Epoch 392/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - accuracy: 0.7721 - loss: 0.4371 - val_accuracy: 0.7718 - val_loss: 0.4372\n",
      "Epoch 393/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - accuracy: 0.7731 - loss: 0.4358 - val_accuracy: 0.7717 - val_loss: 0.4380\n",
      "Epoch 394/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m927s\u001b[0m 657ms/step - accuracy: 0.7702 - loss: 0.4377 - val_accuracy: 0.7726 - val_loss: 0.4363\n",
      "Epoch 395/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.7703 - loss: 0.4387 - val_accuracy: 0.7726 - val_loss: 0.4383\n",
      "Epoch 396/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step - accuracy: 0.7711 - loss: 0.4385 - val_accuracy: 0.7725 - val_loss: 0.4371\n",
      "Epoch 397/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585us/step - accuracy: 0.7681 - loss: 0.4394 - val_accuracy: 0.7712 - val_loss: 0.4397\n",
      "Epoch 398/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7718 - loss: 0.4378 - val_accuracy: 0.7730 - val_loss: 0.4365\n",
      "Epoch 399/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7688 - loss: 0.4388 - val_accuracy: 0.7731 - val_loss: 0.4370\n",
      "Epoch 400/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.7708 - loss: 0.4388 - val_accuracy: 0.7726 - val_loss: 0.4376\n",
      "Epoch 401/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7711 - loss: 0.4389 - val_accuracy: 0.7721 - val_loss: 0.4378\n",
      "Epoch 402/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - accuracy: 0.7690 - loss: 0.4395 - val_accuracy: 0.7733 - val_loss: 0.4375\n",
      "Epoch 403/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - accuracy: 0.7708 - loss: 0.4372 - val_accuracy: 0.7734 - val_loss: 0.4365\n",
      "Epoch 404/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7714 - loss: 0.4374 - val_accuracy: 0.7707 - val_loss: 0.4404\n",
      "Epoch 405/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.7717 - loss: 0.4369 - val_accuracy: 0.7735 - val_loss: 0.4370\n",
      "Epoch 406/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7696 - loss: 0.4381 - val_accuracy: 0.7729 - val_loss: 0.4362\n",
      "Epoch 407/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7703 - loss: 0.4394 - val_accuracy: 0.7725 - val_loss: 0.4369\n",
      "Epoch 408/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - accuracy: 0.7701 - loss: 0.4386 - val_accuracy: 0.7717 - val_loss: 0.4366\n",
      "Epoch 409/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7704 - loss: 0.4374 - val_accuracy: 0.7723 - val_loss: 0.4397\n",
      "Epoch 410/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - accuracy: 0.7695 - loss: 0.4394 - val_accuracy: 0.7706 - val_loss: 0.4403\n",
      "Epoch 411/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7709 - loss: 0.4377 - val_accuracy: 0.7723 - val_loss: 0.4358\n",
      "Epoch 412/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7713 - loss: 0.4367 - val_accuracy: 0.7727 - val_loss: 0.4364\n",
      "Epoch 413/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7714 - loss: 0.4363 - val_accuracy: 0.7731 - val_loss: 0.4363\n",
      "Epoch 414/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7705 - loss: 0.4383 - val_accuracy: 0.7732 - val_loss: 0.4365\n",
      "Epoch 415/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7716 - loss: 0.4371 - val_accuracy: 0.7723 - val_loss: 0.4359\n",
      "Epoch 416/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7710 - loss: 0.4380 - val_accuracy: 0.7729 - val_loss: 0.4370\n",
      "Epoch 417/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589us/step - accuracy: 0.7723 - loss: 0.4359 - val_accuracy: 0.7732 - val_loss: 0.4367\n",
      "Epoch 418/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - accuracy: 0.7720 - loss: 0.4354 - val_accuracy: 0.7737 - val_loss: 0.4383\n",
      "Epoch 419/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - accuracy: 0.7716 - loss: 0.4367 - val_accuracy: 0.7730 - val_loss: 0.4363\n",
      "Epoch 420/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7710 - loss: 0.4382 - val_accuracy: 0.7725 - val_loss: 0.4378\n",
      "Epoch 421/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7708 - loss: 0.4379 - val_accuracy: 0.7717 - val_loss: 0.4378\n",
      "Epoch 422/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7710 - loss: 0.4362 - val_accuracy: 0.7718 - val_loss: 0.4370\n",
      "Epoch 423/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - accuracy: 0.7711 - loss: 0.4374 - val_accuracy: 0.7726 - val_loss: 0.4358\n",
      "Epoch 424/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.7705 - loss: 0.4380 - val_accuracy: 0.7714 - val_loss: 0.4370\n",
      "Epoch 425/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7699 - loss: 0.4384 - val_accuracy: 0.7730 - val_loss: 0.4365\n",
      "Epoch 426/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - accuracy: 0.7728 - loss: 0.4360 - val_accuracy: 0.7726 - val_loss: 0.4370\n",
      "Epoch 427/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - accuracy: 0.7708 - loss: 0.4368 - val_accuracy: 0.7721 - val_loss: 0.4384\n",
      "Epoch 428/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - accuracy: 0.7713 - loss: 0.4362 - val_accuracy: 0.7732 - val_loss: 0.4367\n",
      "Epoch 429/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.7701 - loss: 0.4384 - val_accuracy: 0.7718 - val_loss: 0.4374\n",
      "Epoch 430/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.7718 - loss: 0.4366 - val_accuracy: 0.7722 - val_loss: 0.4375\n",
      "Epoch 431/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587us/step - accuracy: 0.7715 - loss: 0.4377 - val_accuracy: 0.7722 - val_loss: 0.4377\n",
      "Epoch 432/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587us/step - accuracy: 0.7708 - loss: 0.4378 - val_accuracy: 0.7721 - val_loss: 0.4378\n",
      "Epoch 433/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7730 - loss: 0.4359 - val_accuracy: 0.7722 - val_loss: 0.4377\n",
      "Epoch 434/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584us/step - accuracy: 0.7697 - loss: 0.4387 - val_accuracy: 0.7726 - val_loss: 0.4366\n",
      "Epoch 435/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7701 - loss: 0.4367 - val_accuracy: 0.7731 - val_loss: 0.4354\n",
      "Epoch 436/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.7708 - loss: 0.4373 - val_accuracy: 0.7733 - val_loss: 0.4362\n",
      "Epoch 437/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7706 - loss: 0.4383 - val_accuracy: 0.7712 - val_loss: 0.4412\n",
      "Epoch 438/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7726 - loss: 0.4382 - val_accuracy: 0.7731 - val_loss: 0.4355\n",
      "Epoch 439/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.7688 - loss: 0.4392 - val_accuracy: 0.7731 - val_loss: 0.4363\n",
      "Epoch 440/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7719 - loss: 0.4365 - val_accuracy: 0.7724 - val_loss: 0.4367\n",
      "Epoch 441/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7724 - loss: 0.4357 - val_accuracy: 0.7729 - val_loss: 0.4360\n",
      "Epoch 442/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7722 - loss: 0.4361 - val_accuracy: 0.7729 - val_loss: 0.4372\n",
      "Epoch 443/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7717 - loss: 0.4374 - val_accuracy: 0.7719 - val_loss: 0.4378\n",
      "Epoch 444/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7708 - loss: 0.4351 - val_accuracy: 0.7725 - val_loss: 0.4355\n",
      "Epoch 445/800\n",
      "\u001b[1m1413/1413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7685 - loss: 0.4390 - val_accuracy: 0.7714 - val_loss: 0.4400\n",
      "Epoch 446/800\n",
      "\u001b[1m 712/1413\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.7703 - loss: 0.4372"
     ]
    }
   ],
   "source": [
    "if model_testing=='y':\n",
    "    history = model.fit(X_train, y_train, epochs=nepochs, validation_data=(X_test, y_test), batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb3c4e-57fb-4b48-b32f-5f93e351fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_testing=='y':\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b7ae97-a1ea-41e5-b4ad-9a547f81d8a3",
   "metadata": {},
   "source": [
    "## Performance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e22ff4",
   "metadata": {
    "id": "9L7D41IDzc_H",
    "outputId": "f1a7a354-b2ba-4e44-e3d2-e302c0bc271c",
    "papermill": {
     "duration": 1.563959,
     "end_time": "2023-02-17T09:03:05.036615",
     "exception": false,
     "start_time": "2023-02-17T09:03:03.472656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_testing=='y':\n",
    "    # aesthetics\n",
    "    font = {'family' : 'chalkboard',\n",
    "            'weight' : 'bold',\n",
    "            'size'   : 18}\n",
    "    \n",
    "    plt.rc('font', **font)\n",
    "    \n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    ax1 = plt.subplot(121) # qsto sta per 1,2,1 ie nrows, ncol, index\n",
    "    ax2 = plt.subplot(122)\n",
    "    \n",
    "    # what to plot on first figure (ax1)\n",
    "    ax1.plot(history.history['accuracy'], label='Training accuracy') # qua specifico cosa plottare (le y, le x sono implicite in history)\n",
    "    ax1.plot(history.history['val_accuracy'], label = 'Validation accuracy') \n",
    "    \n",
    "    ax1.set_title(\"Training and validation accuracy\")\n",
    "    ax1.set(xlabel='epoch', ylabel='Accuracy')\n",
    "    ax1.legend(loc='lower right')\n",
    "    \n",
    "    # what to plot on first figure (ax1)\n",
    "    ax2.plot(history.history['loss'], label='Training loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation loss')\n",
    "    \n",
    "    ax2.set_title(\"Training and validation loss\")\n",
    "    ax2.set(xlabel='epoch', ylabel='loss')\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    #To check the network accuracy on test data\n",
    "    test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee3bb57-9da0-423d-90de-ab45c5a4992f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fig.savefig('28_12_6_12_28_Adam.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
